{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e preparação de *datasets*\n",
    "\n",
    "O carregamento e preparação de *datasets* é um ótimo exercício para tomarmos conhecimento das ferramentas a serem utilizadas para o processamento de sinais em `python`, seja sinais biológicos quanto de outra natureza, como um som, corrente elétrica, etc.\n",
    "\n",
    "Nesta `notebook` será apresentado o carregamento de um *dataset* público do *website* `UCI - Machine Learning Repository`. O *dataset* a ser utilizado é o `EEG Database Data Set` (https://archive.ics.uci.edu/ml/datasets/EEG+Database).\n",
    "\n",
    "\n",
    "## Descrição do *dataset*:\n",
    "\n",
    "A intenção deste *dataset* é examinar por meio de algoritmos de inteligência computacional a pré-disposição genética que um paciente possui ao alcoolismo.\n",
    "\n",
    "Os principais dados analizados são do tipo *time-series*, em outras palavras, conjuntos de dados que representam um sinal mensurado no domínio do tempo. Os dados são completados com outros atributos como o nome do eletrodo, o número da amostra, etc. Outras informações relevantes do *dataset*:\n",
    "\n",
    "- Quantidade de atributos: 4\n",
    "- Número de instancias: 122\n",
    "- Existem dados faltantes? Sim\n",
    "- Tipos de dados encontrados: categórico, inteiro e real\n",
    "\n",
    "Existem três categorias de dados neste *dataset*:\n",
    "\n",
    "1. Small Data Set: <font color='red'>**descrever**</font>\n",
    "2. Large Data Set: <font color='red'>**descrever**</font>\n",
    "3. Full Data Set: <font color='red'>**descrever**</font>\n",
    "\n",
    "Cada sessão (*trial*) é armazenada da seguinte forma:\n",
    "\n",
    "```\n",
    "# co2a0000364.rd \n",
    "# 120 trials, 64 chans, 416 samples 368 post_stim samples \n",
    "# 3.906000 msecs uV \n",
    "# S1 obj , trial 0 \n",
    "# FP1 chan 0 \n",
    "0 FP1 0 -8.921 \n",
    "0 FP1 1 -8.433 \n",
    "0 FP1 2 -2.574 \n",
    "0 FP1 3 5.239 \n",
    "0 FP1 4 11.587 \n",
    "0 FP1 5 14.028\n",
    "...\n",
    "```\n",
    "\n",
    "As primeiras 4 linhas são de cabeçalho:\n",
    "\n",
    "**linha 1**: identificação do paciente e se ele indica ser um alcoólatra (a) ou controle (c) pela quarta letra (co2**a**0000364);\n",
    "\n",
    "**linha 4**: determina se o paciente foi exposto a um único estímulo (`S1 obj`), a dois estímulos iguais (`S2 match`) ou a dois estímulos diferentes (`S2 no match`);\n",
    "\n",
    "**linha 5**: identifica o início da coleta dos dados pelo eletrodo FP1. As 4 colunas são:\n",
    "\n",
    "```\n",
    "número_da_sessão identificação_do_eletrodo número_da_amostra valor_em_micro_volts\n",
    "```\n",
    "\n",
    "\n",
    "### Realizando o download \n",
    "\n",
    "Primeiro faremos um código para verificar se o *dataset* já foi baixado, caso contrário, executar o código de download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset já baixado!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "import os\n",
    "\n",
    "\n",
    "urls = {\n",
    "    'small': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/smni_eeg_data.tar.gz',\n",
    "    'large_train': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/SMNI_CMI_TRAIN.tar.gz',\n",
    "    'large_test': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/SMNI_CMI_TEST.tar.gz',\n",
    "    'full': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/eeg_full.tar'\n",
    "}\n",
    "\n",
    "# verifica se o diretório dos datasets existe\n",
    "if not os.path.exists('dataset/'):\n",
    "    os.mkdir('dataset/')\n",
    "    for k, v in urls.items():\n",
    "        fn = v.split('/')[-1]\n",
    "        print('Baixando:', fn, '...')\n",
    "        urlretrieve(v, './dataset/{}'.format(fn))\n",
    "    print('Downlod dos datasets concluído!')\n",
    "else:\n",
    "    print('Dataset já baixado!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descompactando pastas e subpastas\n",
    "\n",
    "Agora é necessário descompactar (recursivamente) diversas pastas e subpastas em arquivos GZip. Algumas pastas estão com o arquivo na extensão `.tar`, já outras, `.tar.gz`. Não obstante, algumas subpastas estão compactadas e outras não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/eeg_full.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d451d2e640dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/eeg_full/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tar -xvf dataset/eeg_full.tar -C dataset/eeg_full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/eeg_full.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/**/*.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/eeg_full.tar'"
     ]
    }
   ],
   "source": [
    "from subprocess import getoutput as gop\n",
    "import glob\n",
    "\n",
    "\n",
    "# único arquivo somente empacotado (tar)\n",
    "os.mkdir('dataset/eeg_full/')\n",
    "gop('tar -xvf dataset/eeg_full.tar -C dataset/eeg_full')\n",
    "os.remove('dataset/eeg_full.tar')\n",
    "\n",
    "while glob.glob('dataset/**/*.gz', recursive=True):\n",
    "    # quando o arquivo está empacotado (tar) e compactado (gz)\n",
    "    for f in glob.iglob('dataset/**/*.tar.gz', recursive=True):\n",
    "        gop('tar -zxvf {} -C {}'.format(f, f[:f.rindex('/')]))\n",
    "        os.remove(f)\n",
    "    # quando o arquivo está somente compactado (gz)\n",
    "    for f in glob.iglob('dataset/**/*.gz', recursive=True):\n",
    "        gop('gzip -d {}'.format(f))\n",
    "print('Descompactações finalizadas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando parte do dataset\n",
    "\n",
    "Vamos agora carregar o subconjunto \"small\" do *dataset* e fica como <font color='red'>**tarefa de casa**</font> carregar e preparar todos os outros subconjuntos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/smni_eeg_data' -> 'dataset/small'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a16bf268d761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# organizando melhor as pastas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/smni_eeg_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/eeg_full'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/SMNI_CMI_TRAIN/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/large_train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/SMNI_CMI_TEST/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/large_test/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/smni_eeg_data' -> 'dataset/small'"
     ]
    }
   ],
   "source": [
    "# organizando melhor as pastas\n",
    "os.rename('dataset/smni_eeg_data', 'dataset/small')\n",
    "os.rename('dataset/eeg_full', 'dataset/full')\n",
    "os.rename('dataset/SMNI_CMI_TRAIN/', 'dataset/large_train/')\n",
    "os.rename('dataset/SMNI_CMI_TEST/', 'dataset/large_test/')\n",
    "print(gop('ls -l dataset/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-105063492454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mre\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# identificando pastas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m folders = {\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from re import search\n",
    "import numpy as np\n",
    "\n",
    "# identificando pastas\n",
    "folders = {\n",
    "    'small': 'dataset/small',\n",
    "    'large_train': 'dataset/large_train',\n",
    "    'large_test': 'dataset/large_test',\n",
    "    'full': 'dataset/full',\n",
    "}\n",
    "# carregando pasta \"small\"\n",
    "small_dir = gop('ls {}'.format(folders['small'])).split('\\n')\n",
    "# 1ª dimensão dos dados contendo os sujeitos. Ex.: C_1, a_m, etc\n",
    "subjects = list()\n",
    "for types in small_dir:\n",
    "    files = gop('ls {}/{}'.format(folders['small'], types)).split('\\n')\n",
    "    # 2ª dimensão dos dados contendo as sessões (trials)\n",
    "    trials = list()\n",
    "    for f in files:\n",
    "        arquivo = open('{}/{}/{}'.format(folders['small'], types, f))\n",
    "        text = arquivo.readlines()\n",
    "        # 3ª dimensão dos dados contendo os canais (eletrodos)\n",
    "        chs = list()\n",
    "        # 4ª dimensão dos dados contendo os valores em milivolts\n",
    "        values = list()\n",
    "        for line in text:\n",
    "            # ex: \"# FP1 chan 0\"\n",
    "            t = search('\\w{1,3} chan \\d{1,2}', line)\n",
    "            # ex: \"0 FP1 0 -8.921\"\n",
    "            p = search('^\\d{1,2}\\ \\w{1,3}\\ \\d{1,3}\\ (?P<value>.+$)', line)\n",
    "            if p:\n",
    "                values.append(float(p.group('value')))\n",
    "            # mudou para outro eletrodo\n",
    "            elif t and values:\n",
    "                chs.append(values)\n",
    "                values = list()\n",
    "        chs.append(values)\n",
    "        trials.append(chs)\n",
    "        arquivo.close()\n",
    "    subjects.append(trials)\n",
    "data = np.array(subjects)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados carregados...\n",
    "\n",
    "Os dados \"single\" foram dividos da seguinte forma:\n",
    "```\n",
    "[experimentos, triagens, canais, amostras]\n",
    "```\n",
    "formando um `numpy.array` de quatro dimensões.\n",
    "\n",
    "Em seguida, vamos plotar esses dados para \"tentar\" visualizar algum padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8874b3f8b664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "d1 = list()\n",
    "d2 = list()\n",
    "\n",
    "for e in range(64):\n",
    "    for i, t in enumerate(np.linspace(0, 1, 256)):\n",
    "        d1.append([e, t, data[0][0][e][i]])\n",
    "        d2.append([e, t, data[1][0][e][i]])\n",
    "d1 = np.array(d1)\n",
    "d2 = np.array(d2)\n",
    "x1, y1, z1 = d1[:,0], d1[:,1], d1[:,2]\n",
    "x2, y2, z2 = d2[:,0], d2[:,1], d2[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "surf = ax.plot_trisurf(x1, y1, z1, cmap=cm.inferno, linewidth=1)\n",
    "ax.set_xlabel('Canais')\n",
    "ax.set_ylabel('Tempo (seg.)')\n",
    "ax.set_zlabel('Milivolts')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "surf = ax.plot_trisurf(x2, y2, z2, cmap=cm.inferno, linewidth=1)\n",
    "ax.set_xlabel('Canais')\n",
    "ax.set_ylabel('Tempo (seg.)')\n",
    "ax.set_zlabel('Milivolts')\n",
    "\n",
    "fig.colorbar(surf)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuação...\n",
    "\n",
    "- Melhorar os comentários no códigos\n",
    "- Modificar a visualização do gráfico **de** um *trial* fixo **para** a média de todos os *trials*\n",
    "    - Fatorar o código o máximo possível (evitar loops desnecessários com o uso de `numpy`\n",
    "    - Criar mais `subplots` para comparar a visualização\n",
    "- Gravar os dados carregados em arquivo(s) CSV de um jeito mais fácil de carregar novamente\n",
    "- Fazer o código para os arquivos \"large\": os arquivos estão divididos em **treino** e **teste** (próximo passo do curso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
